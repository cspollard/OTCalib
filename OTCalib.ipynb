{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kC2NF4bZLMlb",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x720 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from math import e\n",
    "\n",
    "device='cuda'\n",
    "\n",
    "\n",
    "def poly(cs, xs):\n",
    "  ys = torch.zeros_like(xs)\n",
    "  for (i, c) in enumerate(cs):\n",
    "    ys += c * xs**i\n",
    "\n",
    "  return ys\n",
    "\n",
    "\n",
    "def discMC(xs, logpts):\n",
    "  return poly([0, 0.6, 1.2, 1.1], xs) * poly([1, 0.1, -0.01], logpts)\n",
    "\n",
    "def discData(xs, logpts):\n",
    "  return poly([0, 0.7, 1.1, 1.3], xs) * poly([1, -0.1, 0.02], logpts)\n",
    "\n",
    "\n",
    "def logptMC(xs):\n",
    "  return torch.log(poly([25, 100, 7], -torch.log(xs)))\n",
    "\n",
    "def logptData(xs):\n",
    "  return torch.log(poly([25, 120, 5], -torch.log(xs)))\n",
    "\n",
    "\n",
    "\n",
    "# need to add a small number to avoid values of zero.\n",
    "def genMC(n):\n",
    "  xs = torch.rand(n, device=device) + 1e-5\n",
    "  logpts = logptMC(xs)\n",
    "  ys = torch.rand(n, device=device) + 1e-5\n",
    "  ds = discMC(ys, logpts)\n",
    "  return torch.stack([ds, logpts]).transpose(0, 1)\n",
    "\n",
    "def genData(n):\n",
    "  xs = torch.rand(n, device=device) + 1e-5\n",
    "  logpts = logptData(xs)\n",
    "  ys = torch.rand(n, device=device) + 1e-5\n",
    "  ds = discData(ys, logpts)\n",
    "  return torch.stack([ds, logpts]).transpose(0, 1)\n",
    "\n",
    "\n",
    "\n",
    "# give high-pT jets more weight to improve convergence\n",
    "# similar idea to boosting\n",
    "def ptWeight(logpts):\n",
    "    pts = torch.exp(logpts)\n",
    "    w = torch.exp(pts / e**5.5)\n",
    "    return w / torch.mean(w)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def test(n):\n",
    "  mc = genMC(n).cpu().numpy()\n",
    "  data = genData(n).cpu().numpy()\n",
    "    \n",
    "  mcw = ptWeight(torch.tensor(mc[:,1])).numpy()\n",
    "  dataw = ptWeight(torch.tensor(data[:,1])).numpy()\n",
    "\n",
    "\n",
    "  plt.figure(figsize=(30, 10))\n",
    "\n",
    "  plt.subplot(1, 3, 1)\n",
    "\n",
    "  _ = plt.hist([np.exp(mc[:,1]), np.exp(data[:,1])], bins=25, label=[\"mc\", \"data\"], weights=[mcw, dataw])\n",
    "  plt.title(\"pT\")\n",
    "  plt.yscale(\"log\")\n",
    "  plt.legend()\n",
    "\n",
    "  plt.subplot(1, 3, 2)\n",
    "\n",
    "\n",
    "  _ = plt.hist([mc[:,1], data[:,1]], bins=25, label=[\"mc\", \"data\"])\n",
    "  plt.title(\"log pT\")\n",
    "  plt.legend()\n",
    "\n",
    "  plt.subplot(1, 3, 3)\n",
    "\n",
    "  _ = plt.hist([mc[:,0], data[:,0]], bins=25, label=[\"mc\", \"data\"])\n",
    "  plt.title(\"discriminant\")\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "test(int(1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RacvVN4HTDdW"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "\n",
    "    \n",
    "    \n",
    "lnlatentadv = 9\n",
    "\n",
    "\n",
    "def layer(n, m, act):\n",
    "  return \\\n",
    "    nn.Sequential(\n",
    "        nn.Linear(n, m)\n",
    "      , act(inplace=True)\n",
    "    )\n",
    "\n",
    "\n",
    "def sequential(xs):\n",
    "    d = OrderedDict()\n",
    "    for (i, x) in enumerate(xs):\n",
    "        d[str(i)] = x\n",
    "        \n",
    "    return nn.Sequential(d)\n",
    "\n",
    "\n",
    "def fullyConnected(nl, n0, nmid, nf, act):\n",
    "  return \\\n",
    "    nn.Sequential(\n",
    "        nn.Linear(n0, nmid)\n",
    "      , act(inplace=True)\n",
    "      , sequential([layer(nmid, nmid, act) for i in range(nl)])\n",
    "      , nn.Linear(nmid, nf)\n",
    "      )\n",
    "\n",
    "\n",
    "def tloss(xs):\n",
    "  return torch.mean(xs**2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qldJqWitEJY-"
   },
   "outputs": [],
   "source": [
    "def save():\n",
    "  torch.save(\n",
    "      { 'transport_state_dict' : transport.state_dict()\n",
    "      , 'adversary_state_dict' : adversary.state_dict()\n",
    "      , 'toptim_state_dict' : toptim.state_dict()\n",
    "      , 'aoptim_state_dict' : aoptim.state_dict()\n",
    "      }\n",
    "    , \"./OTCalib.gaus.pth\"\n",
    "  )\n",
    "\n",
    "def load():\n",
    "  checkpoint = torch.load(\"./OTCalib.gaus.pth\")\n",
    "  transport.load_state_dict(checkpoint[\"transport_state_dict\"])\n",
    "  adversary.load_state_dict(checkpoint[\"adversary_state_dict\"])\n",
    "  toptim.load_state_dict(checkpoint[\"toptim_state_dict\"])\n",
    "  aoptim.load_state_dict(checkpoint[\"aoptim_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uuuYHqdlNKu7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.nn.functional import binary_cross_entropy_with_logits\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from math import log, exp\n",
    "\n",
    "def tonp(xs):\n",
    "  return xs.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "def plotPtTheta(pt, toys, writer, label, epoch):\n",
    "  logpt = log(pt)\n",
    "\n",
    "  zeros = torch.zeros((toys.size()[0], nps), device=device)\n",
    "  logpts = torch.ones(toys.size()[0], device=device)*logpt\n",
    "\n",
    "  data = torch.stack([torch.sort(discData(toys, logpts))[0], logpts]).transpose(0, 1)\n",
    "  mc = torch.stack([torch.sort(discMC(toys, logpts))[0], logpts]).transpose(0, 1)\n",
    "\n",
    "  thetas = zeros.clone()\n",
    "  transporting = trans(mc, thetas)\n",
    "  nomtrans = tonp(transporting)\n",
    "  nom = tonp(transporting + mc[:,0:1])\n",
    "\n",
    "  postrans = []\n",
    "  negtrans = []\n",
    "  pos = []\n",
    "  neg = []\n",
    "  for i in range(nps):\n",
    "    thetas = zeros.clone()\n",
    "    thetas[:,i] = 1\n",
    "    transporting = trans(mc, thetas)\n",
    "    postrans.append(tonp(transporting))\n",
    "    pos.append(tonp(transporting + mc[:,0:1])[:,0])\n",
    "\n",
    "    thetas = zeros.clone()\n",
    "    thetas[:,i] = -1\n",
    "    transporting = trans(mc, thetas)\n",
    "    negtrans.append(tonp(transporting))\n",
    "    neg.append(tonp(transporting + mc[:,0:1])[:,0])\n",
    "\n",
    "\n",
    "\n",
    "  data = tonp(data)\n",
    "  mc = tonp(mc)\n",
    "\n",
    "  fig = plt.figure(figsize=(6, 6))\n",
    "\n",
    "  rangex = (0, 5)\n",
    "  rangey = (-1, 1)\n",
    "\n",
    "  h, b, _ = plt.hist( \\\n",
    "        [mc[:,0], nom[:,0], data[:,0]]\n",
    "      , bins=25\n",
    "      , range=rangex\n",
    "      , density=True\n",
    "      , label=[\"mc\", \"nominal transported\", \"data\"]\n",
    "      )\n",
    "  \n",
    "  plt.title(\"discriminant distribution, (pT = %0.2f)\" % exp(logpt))\n",
    "  plt.xlabel(\"discriminant\")\n",
    "  plt.legend()\n",
    "    \n",
    "  writer.add_figure(\"%shist\" % label, fig, global_step=epoch)\n",
    "  plt.close()\n",
    "    \n",
    "    \n",
    "  cols = [\"blue\", \"green\", \"red\", \"orange\", \"magenta\"]\n",
    "\n",
    "  hpos, _, _ = plt.hist( \\\n",
    "        pos\n",
    "      , bins=b\n",
    "      , range=rangex\n",
    "      , density=True\n",
    "      )\n",
    "  \n",
    "  hneg, _, _ = plt.hist( \\\n",
    "        neg\n",
    "      , bins=b\n",
    "      , range=rangex\n",
    "      , density=True\n",
    "      )\n",
    "  \n",
    "\n",
    "  fig = plt.figure(figsize=(6, 6))\n",
    "\n",
    "  for (i, hvar) in enumerate(hpos):\n",
    "    _ = plt.plot( \\\n",
    "          (b[:-1] + b[1:]) / 2.0\n",
    "        , hvar - h[2]\n",
    "        , linewidth=1\n",
    "        , color=cols[i]\n",
    "        , linestyle='dashed'\n",
    "        )\n",
    "    \n",
    "  for (i, hvar) in enumerate(hneg):\n",
    "    _ = plt.plot( \\\n",
    "          (b[:-1] + b[1:]) / 2.0\n",
    "        , hvar - h[2]\n",
    "        , linewidth=1\n",
    "        , color=cols[i]\n",
    "        , linestyle='dashed'\n",
    "        )\n",
    "    \n",
    "\n",
    "  _ = plt.plot( \\\n",
    "        (b[:-1] + b[1:]) / 2.0\n",
    "      , h[0] - h[2]\n",
    "      , label=\"mc\"\n",
    "      , linewidth=3\n",
    "      )\n",
    "\n",
    "  _ = plt.plot( \\\n",
    "        (b[:-1] + b[1:]) / 2.0\n",
    "      , h[1] - h[2]\n",
    "      , label=\"nominal transported\"\n",
    "      , linewidth=3\n",
    "      )\n",
    "\n",
    "\n",
    "\n",
    "  plt.ylim(-0.5, 0.5)\n",
    "  plt.title(\"discriminant difference to data, (pT = %0.2f)\" % exp(logpt))\n",
    "  plt.xlabel(\"discriminant\")\n",
    "  plt.ylabel(\"prediction - data\")\n",
    "  plt.legend()\n",
    "    \n",
    "  writer.add_figure(\"%sdiff\" % label, fig, global_step=epoch)\n",
    "  plt.close()\n",
    "    \n",
    "\n",
    "\n",
    "  fig = plt.figure(figsize=(6, 6))\n",
    "  \n",
    "  for i in range(nps):\n",
    "    _ = \\\n",
    "      plt.plot(\n",
    "          mc[:,0]\n",
    "        , postrans[i]\n",
    "        , c=cols[i]\n",
    "      )\n",
    "\n",
    "    _ = \\\n",
    "      plt.plot(\n",
    "          mc[:,0]\n",
    "        , negtrans[i]\n",
    "        , c=cols[i]\n",
    "      )\n",
    "\n",
    "\n",
    "  _ = \\\n",
    "    plt.plot(\n",
    "        mc[:,0]\n",
    "      , nomtrans\n",
    "      , c=\"black\"\n",
    "      , lw=4\n",
    "    )\n",
    "\n",
    "\n",
    "  \n",
    "  plt.xlim(rangex)\n",
    "  plt.ylim(rangey)\n",
    "  plt.title(\"discriminant transport, (pT = %0.2f)\" % exp(logpt))\n",
    "  plt.xlabel(\"mc discriminant\")\n",
    "  plt.ylabel(\"transport vector\")\n",
    "    \n",
    "\n",
    "        \n",
    "  writer.add_figure(\"%strans\" % label, fig, global_step=epoch)\n",
    "  plt.close()\n",
    "    \n",
    "  return\n",
    "\n",
    "\n",
    "\n",
    "def trans(mc, thetas):\n",
    "    tmp = transport(mc)\n",
    "    cv = tmp[:,0].unsqueeze(1)\n",
    "    coeffs = tmp[:,1:]\n",
    "    \n",
    "    corr = torch.bmm(thetas.unsqueeze(1), coeffs.unsqueeze(2))\n",
    "    \n",
    "    # TODO\n",
    "    # would this be easier to learn if it were\n",
    "    # (1 - sum(thetas)) * cv + corr?\n",
    "    return cv + corr.squeeze(2)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "epoch: 3\n",
      "epoch: 4\n",
      "epoch: 5\n",
      "epoch: 6\n",
      "epoch: 7\n",
      "epoch: 8\n",
      "epoch: 9\n",
      "epoch: 10\n",
      "epoch: 11\n",
      "epoch: 12\n",
      "epoch: 13\n",
      "epoch: 14\n",
      "epoch: 15\n",
      "epoch: 16\n",
      "epoch: 17\n",
      "epoch: 18\n",
      "epoch: 19\n",
      "epoch: 20\n",
      "epoch: 21\n",
      "epoch: 22\n",
      "epoch: 23\n",
      "epoch: 24\n",
      "epoch: 25\n",
      "epoch: 26\n",
      "epoch: 27\n",
      "epoch: 28\n",
      "epoch: 29\n",
      "epoch: 30\n",
      "epoch: 31\n",
      "epoch: 32\n",
      "epoch: 33\n",
      "epoch: 34\n",
      "epoch: 35\n",
      "epoch: 36\n",
      "epoch: 37\n",
      "epoch: 38\n",
      "epoch: 39\n",
      "epoch: 40\n",
      "epoch: 41\n",
      "epoch: 42\n",
      "epoch: 43\n",
      "epoch: 44\n",
      "epoch: 45\n",
      "epoch: 46\n",
      "epoch: 47\n",
      "epoch: 48\n",
      "epoch: 49\n",
      "epoch: 50\n",
      "epoch: 51\n",
      "epoch: 52\n",
      "epoch: 53\n",
      "epoch: 54\n",
      "epoch: 55\n",
      "epoch: 56\n",
      "epoch: 57\n",
      "epoch: 58\n",
      "epoch: 59\n",
      "epoch: 60\n",
      "epoch: 61\n",
      "epoch: 62\n",
      "epoch: 63\n",
      "epoch: 64\n",
      "epoch: 65\n",
      "epoch: 66\n",
      "epoch: 67\n",
      "epoch: 68\n",
      "epoch: 69\n",
      "epoch: 70\n",
      "epoch: 71\n",
      "epoch: 72\n",
      "epoch: 73\n",
      "epoch: 74\n",
      "epoch: 75\n",
      "epoch: 76\n",
      "epoch: 77\n",
      "epoch: 78\n",
      "epoch: 79\n",
      "epoch: 80\n",
      "epoch: 81\n",
      "epoch: 82\n",
      "epoch: 83\n",
      "epoch: 84\n",
      "epoch: 85\n",
      "epoch: 86\n",
      "epoch: 87\n",
      "epoch: 88\n",
      "epoch: 89\n",
      "epoch: 90\n",
      "epoch: 91\n",
      "epoch: 92\n",
      "epoch: 93\n",
      "epoch: 94\n",
      "epoch: 95\n",
      "epoch: 96\n",
      "epoch: 97\n",
      "epoch: 98\n",
      "epoch: 99\n",
      "epoch: 100\n",
      "epoch: 101\n",
      "epoch: 102\n",
      "epoch: 103\n",
      "epoch: 104\n",
      "epoch: 105\n",
      "epoch: 106\n",
      "epoch: 107\n",
      "epoch: 108\n",
      "epoch: 109\n",
      "epoch: 110\n",
      "epoch: 111\n",
      "epoch: 112\n",
      "epoch: 113\n",
      "epoch: 114\n",
      "epoch: 115\n",
      "epoch: 116\n",
      "epoch: 117\n",
      "epoch: 118\n",
      "epoch: 119\n",
      "epoch: 120\n",
      "epoch: 121\n",
      "epoch: 122\n",
      "epoch: 123\n",
      "epoch: 124\n",
      "epoch: 125\n",
      "epoch: 126\n",
      "epoch: 127\n",
      "epoch: 128\n",
      "epoch: 129\n",
      "epoch: 130\n",
      "epoch: 131\n",
      "epoch: 132\n",
      "epoch: 133\n",
      "epoch: 134\n",
      "epoch: 135\n",
      "epoch: 136\n",
      "epoch: 137\n",
      "epoch: 138\n",
      "epoch: 139\n",
      "epoch: 140\n",
      "epoch: 141\n",
      "epoch: 142\n",
      "epoch: 143\n",
      "epoch: 144\n",
      "epoch: 145\n",
      "epoch: 146\n",
      "epoch: 147\n",
      "epoch: 148\n",
      "epoch: 149\n",
      "epoch: 150\n",
      "epoch: 151\n",
      "epoch: 152\n",
      "epoch: 153\n",
      "epoch: 154\n",
      "epoch: 155\n",
      "epoch: 156\n",
      "epoch: 157\n",
      "epoch: 158\n",
      "epoch: 159\n",
      "epoch: 160\n",
      "epoch: 161\n",
      "epoch: 162\n",
      "epoch: 163\n",
      "epoch: 164\n",
      "epoch: 165\n",
      "epoch: 166\n",
      "epoch: 167\n",
      "epoch: 168\n",
      "epoch: 169\n",
      "epoch: 170\n",
      "epoch: 171\n",
      "epoch: 172\n",
      "epoch: 173\n",
      "epoch: 174\n",
      "epoch: 175\n",
      "epoch: 176\n",
      "epoch: 177\n",
      "epoch: 178\n",
      "epoch: 179\n",
      "epoch: 180\n",
      "epoch: 181\n",
      "epoch: 182\n",
      "epoch: 183\n",
      "epoch: 184\n",
      "epoch: 185\n",
      "epoch: 186\n",
      "epoch: 187\n",
      "epoch: 188\n",
      "epoch: 189\n",
      "epoch: 190\n",
      "epoch: 191\n",
      "epoch: 192\n",
      "epoch: 193\n",
      "epoch: 194\n",
      "epoch: 195\n",
      "epoch: 196\n",
      "epoch: 197\n",
      "epoch: 198\n",
      "epoch: 199\n",
      "epoch: 0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "epoch: 3\n",
      "epoch: 4\n",
      "epoch: 5\n",
      "epoch: 6\n",
      "epoch: 7\n",
      "epoch: 8\n",
      "epoch: 9\n",
      "epoch: 10\n",
      "epoch: 11\n",
      "epoch: 12\n",
      "epoch: 13\n",
      "epoch: 14\n",
      "epoch: 15\n",
      "epoch: 16\n",
      "epoch: 17\n",
      "epoch: 18\n",
      "epoch: 19\n",
      "epoch: 20\n",
      "epoch: 21\n",
      "epoch: 22\n",
      "epoch: 23\n",
      "epoch: 24\n",
      "epoch: 25\n",
      "epoch: 26\n",
      "epoch: 27\n",
      "epoch: 28\n",
      "epoch: 29\n",
      "epoch: 30\n",
      "epoch: 31\n",
      "epoch: 32\n",
      "epoch: 33\n",
      "epoch: 34\n",
      "epoch: 35\n",
      "epoch: 36\n",
      "epoch: 37\n",
      "epoch: 38\n",
      "epoch: 39\n",
      "epoch: 40\n",
      "epoch: 41\n",
      "epoch: 42\n",
      "epoch: 43\n",
      "epoch: 44\n",
      "epoch: 45\n",
      "epoch: 46\n",
      "epoch: 47\n",
      "epoch: 48\n",
      "epoch: 49\n",
      "epoch: 50\n",
      "epoch: 51\n",
      "epoch: 52\n",
      "epoch: 53\n",
      "epoch: 54\n",
      "epoch: 55\n",
      "epoch: 56\n",
      "epoch: 57\n",
      "epoch: 58\n",
      "epoch: 59\n",
      "epoch: 60\n",
      "epoch: 61\n",
      "epoch: 62\n",
      "epoch: 63\n",
      "epoch: 64\n",
      "epoch: 65\n",
      "epoch: 66\n",
      "epoch: 67\n",
      "epoch: 68\n",
      "epoch: 69\n",
      "epoch: 70\n",
      "epoch: 71\n",
      "epoch: 72\n",
      "epoch: 73\n",
      "epoch: 74\n",
      "epoch: 75\n",
      "epoch: 76\n",
      "epoch: 77\n",
      "epoch: 78\n",
      "epoch: 79\n",
      "epoch: 80\n",
      "epoch: 81\n",
      "epoch: 82\n",
      "epoch: 83\n",
      "epoch: 84\n",
      "epoch: 85\n",
      "epoch: 86\n",
      "epoch: 87\n",
      "epoch: 88\n",
      "epoch: 89\n",
      "epoch: 90\n",
      "epoch: 91\n",
      "epoch: 92\n",
      "epoch: 93\n",
      "epoch: 94\n",
      "epoch: 95\n",
      "epoch: 96\n",
      "epoch: 97\n",
      "epoch: 98\n",
      "epoch: 99\n",
      "epoch: 100\n",
      "epoch: 101\n",
      "epoch: 102\n",
      "epoch: 103\n",
      "epoch: 104\n",
      "epoch: 105\n",
      "epoch: 106\n",
      "epoch: 107\n",
      "epoch: 108\n",
      "epoch: 109\n",
      "epoch: 110\n",
      "epoch: 111\n",
      "epoch: 112\n",
      "epoch: 113\n",
      "epoch: 114\n",
      "epoch: 115\n",
      "epoch: 116\n",
      "epoch: 117\n",
      "epoch: 118\n",
      "epoch: 119\n",
      "epoch: 120\n",
      "epoch: 121\n",
      "epoch: 122\n",
      "epoch: 123\n",
      "epoch: 124\n",
      "epoch: 125\n",
      "epoch: 126\n",
      "epoch: 127\n",
      "epoch: 128\n",
      "epoch: 129\n",
      "epoch: 130\n",
      "epoch: 131\n",
      "epoch: 132\n",
      "epoch: 133\n",
      "epoch: 134\n",
      "epoch: 135\n",
      "epoch: 136\n",
      "epoch: 137\n",
      "epoch: 138\n",
      "epoch: 139\n",
      "epoch: 140\n",
      "epoch: 141\n",
      "epoch: 142\n",
      "epoch: 143\n",
      "epoch: 144\n",
      "epoch: 145\n",
      "epoch: 146\n",
      "epoch: 147\n",
      "epoch: 148\n",
      "epoch: 149\n",
      "epoch: 150\n",
      "epoch: 151\n",
      "epoch: 152\n",
      "epoch: 153\n",
      "epoch: 154\n",
      "epoch: 155\n",
      "epoch: 156\n",
      "epoch: 157\n",
      "epoch: 158\n",
      "epoch: 159\n",
      "epoch: 160\n",
      "epoch: 161\n",
      "epoch: 162\n",
      "epoch: 163\n",
      "epoch: 164\n",
      "epoch: 165\n",
      "epoch: 166\n",
      "epoch: 167\n",
      "epoch: 168\n",
      "epoch: 169\n",
      "epoch: 170\n",
      "epoch: 171\n",
      "epoch: 172\n",
      "epoch: 173\n",
      "epoch: 174\n",
      "epoch: 175\n",
      "epoch: 176\n",
      "epoch: 177\n",
      "epoch: 178\n",
      "epoch: 179\n",
      "epoch: 180\n",
      "epoch: 181\n",
      "epoch: 182\n",
      "epoch: 183\n",
      "epoch: 184\n",
      "epoch: 185\n",
      "epoch: 186\n",
      "epoch: 187\n",
      "epoch: 188\n",
      "epoch: 189\n",
      "epoch: 190\n",
      "epoch: 191\n",
      "epoch: 192\n",
      "epoch: 193\n",
      "epoch: 194\n",
      "epoch: 195\n",
      "epoch: 196\n",
      "epoch: 197\n",
      "epoch: 198\n",
      "epoch: 199\n",
      "epoch: 0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "epoch: 3\n",
      "epoch: 4\n",
      "epoch: 5\n",
      "epoch: 6\n",
      "epoch: 7\n",
      "epoch: 8\n",
      "epoch: 9\n",
      "epoch: 10\n",
      "epoch: 11\n",
      "epoch: 12\n",
      "epoch: 13\n",
      "epoch: 14\n",
      "epoch: 15\n",
      "epoch: 16\n",
      "epoch: 17\n",
      "epoch: 18\n",
      "epoch: 19\n",
      "epoch: 20\n",
      "epoch: 21\n",
      "epoch: 22\n",
      "epoch: 23\n",
      "epoch: 24\n",
      "epoch: 25\n",
      "epoch: 26\n",
      "epoch: 27\n",
      "epoch: 28\n",
      "epoch: 29\n",
      "epoch: 30\n",
      "epoch: 31\n",
      "epoch: 32\n",
      "epoch: 33\n",
      "epoch: 34\n",
      "epoch: 35\n",
      "epoch: 36\n",
      "epoch: 37\n",
      "epoch: 38\n",
      "epoch: 39\n",
      "epoch: 40\n",
      "epoch: 41\n",
      "epoch: 42\n",
      "epoch: 43\n",
      "epoch: 44\n",
      "epoch: 45\n",
      "epoch: 46\n",
      "epoch: 47\n",
      "epoch: 48\n",
      "epoch: 49\n",
      "epoch: 50\n",
      "epoch: 51\n",
      "epoch: 52\n",
      "epoch: 53\n",
      "epoch: 54\n",
      "epoch: 55\n",
      "epoch: 56\n",
      "epoch: 57\n",
      "epoch: 58\n",
      "epoch: 59\n",
      "epoch: 60\n",
      "epoch: 61\n",
      "epoch: 62\n",
      "epoch: 63\n",
      "epoch: 64\n",
      "epoch: 65\n",
      "epoch: 66\n",
      "epoch: 67\n",
      "epoch: 68\n",
      "epoch: 69\n",
      "epoch: 70\n",
      "epoch: 71\n",
      "epoch: 72\n",
      "epoch: 73\n",
      "epoch: 74\n",
      "epoch: 75\n",
      "epoch: 76\n",
      "epoch: 77\n",
      "epoch: 78\n",
      "epoch: 79\n",
      "epoch: 80\n",
      "epoch: 81\n",
      "epoch: 82\n",
      "epoch: 83\n",
      "epoch: 84\n",
      "epoch: 85\n",
      "epoch: 86\n",
      "epoch: 87\n",
      "epoch: 88\n",
      "epoch: 89\n",
      "epoch: 90\n",
      "epoch: 91\n",
      "epoch: 92\n",
      "epoch: 93\n",
      "epoch: 94\n",
      "epoch: 95\n",
      "epoch: 96\n",
      "epoch: 97\n",
      "epoch: 98\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "# toys for validation samples\n",
    "nval = 2**15\n",
    "valtoys = torch.rand(nval, device=device)\n",
    "\n",
    "\n",
    "nepochs = 200\n",
    "datasize = 2**18\n",
    "\n",
    "alldata = genData(datasize)\n",
    "allmc = genMC(datasize)\n",
    "\n",
    "\n",
    "acts = [(\"lrelu\", nn.LeakyReLU)] #, (\"sig\", nn.Sigmoid), (\"tanh\", nn.Tanh)]\n",
    "bss = [2**n for n in [10, 12, 8]]\n",
    "npss = [5]\n",
    "nlayer = [4]\n",
    "latent = [1024, 512, 256]\n",
    "lrs = [(5e-5, 10**l) for l in [-6.5, -7, -6, -5.5]]\n",
    "\n",
    "\n",
    "\n",
    "for ((actname, activation), batchsize, nps, nlay, nlat, (alr, tlr)) \\\n",
    "  in product(acts, bss, npss, nlayer, latent, lrs):\n",
    "    \n",
    "    nbatches = datasize // batchsize\n",
    "\n",
    "    \n",
    "    transport = fullyConnected(nlay, 2, nlat, 1+nps, activation)\n",
    "\n",
    "    adversary = fullyConnected(3, 2, 512, 1, nn.LeakyReLU)\n",
    "\n",
    "\n",
    "    transport.to(device)\n",
    "    adversary.to(device)\n",
    "    \n",
    "    toptim = torch.optim.Adam(transport.parameters(), lr=tlr)\n",
    "    aoptim = torch.optim.Adam(adversary.parameters(), lr=alr)\n",
    "\n",
    "    writer = SummaryWriter(\"runs/scan5_%s_%d_%d_%d_%d_%0.2e\" % (actname, batchsize, nps, nlay, nlat, tlr))\n",
    "\n",
    "\n",
    "    for epoch in range(nepochs):\n",
    "      radvloss = 0\n",
    "      fadvloss = 0\n",
    "      tadvloss = 0\n",
    "      ttransloss = 0\n",
    "      realavg = 0\n",
    "      fakeavg = 0\n",
    "\n",
    "      print(\"epoch:\", epoch)\n",
    "\n",
    "      for batch in range(nbatches):\n",
    "\n",
    "        tmp = alldata[torch.randint(alldata.size()[0], size=(batchsize,), device=device)]\n",
    "        data = tmp\n",
    "\n",
    "        tmp = allmc[torch.randint(allmc.size()[0], size=(batchsize,), device=device)]\n",
    "        mc = tmp\n",
    "\n",
    "        toptim.zero_grad()\n",
    "        aoptim.zero_grad()\n",
    "\n",
    "        real = adversary(data)\n",
    "        realavg += torch.mean(real).item()\n",
    "\n",
    "        tmp1 = \\\n",
    "          binary_cross_entropy_with_logits( \\\n",
    "              real\n",
    "            , torch.ones_like(real)\n",
    "            , reduction='mean'\n",
    "            , weight=ptWeight(data[:,1:])\n",
    "            )\n",
    "\n",
    "        radvloss += tmp1.item()\n",
    "\n",
    "        # add gradient regularization\n",
    "        grad_params = torch.autograd.grad(tmp1, adversary.parameters(), create_graph=True, retain_graph=True)\n",
    "        grad_norm = 0\n",
    "        for grad in grad_params:\n",
    "            grad_norm += grad.pow(2).sum()\n",
    "        grad_norm = grad_norm.sqrt()\n",
    "\n",
    "        thetas = torch.randn((batchsize, nps), device=device)\n",
    "        transporting = trans(mc, thetas)\n",
    "\n",
    "        transported = transporting + mc[:,0:1]\n",
    "\n",
    "        fake = adversary(torch.cat([transported, mc[:,1:]], axis=1))\n",
    "\n",
    "\n",
    "        fakeavg += torch.mean(fake).item()\n",
    "\n",
    "\n",
    "\n",
    "        tmp2 = \\\n",
    "          binary_cross_entropy_with_logits( \\\n",
    "              fake\n",
    "            , torch.zeros_like(real)\n",
    "            , reduction='mean'\n",
    "            , weight=ptWeight(mc[:,1:])\n",
    "            )\n",
    "\n",
    "        fadvloss += tmp2.item()\n",
    "\n",
    "        loss = tmp1 + tmp2 + 0.1*grad_norm\n",
    "\n",
    "        loss.backward()\n",
    "        aoptim.step()\n",
    "\n",
    "\n",
    "\n",
    "        toptim.zero_grad()\n",
    "        aoptim.zero_grad()\n",
    "\n",
    "        thetas = torch.randn((batchsize, nps), device=device)\n",
    "        transporting = trans(mc, thetas)\n",
    "\n",
    "        transported = transporting + mc[:,0:1]\n",
    "        fake = adversary(torch.cat([transported, mc[:,1:]], axis=1))\n",
    "\n",
    "        tmp1 = tloss(transporting)\n",
    "        ttransloss += tmp1.item()\n",
    "\n",
    "        tmp2 = \\\n",
    "          binary_cross_entropy_with_logits( \\\n",
    "              fake\n",
    "            , torch.ones_like(real)\n",
    "            , reduction='mean'\n",
    "            , weight=ptWeight(mc[:,1:])\n",
    "            )\n",
    "\n",
    "        tadvloss += tmp2.item()\n",
    "\n",
    "        loss = tmp2 # tmp1 + tmp2\n",
    "\n",
    "        loss.backward()\n",
    "        toptim.step()\n",
    "\n",
    "\n",
    "      # write tensorboard info once per epoch\n",
    "      writer.add_scalar('radvloss', radvloss / nbatches, epoch)\n",
    "      writer.add_scalar('fadvloss', fadvloss / nbatches, epoch)\n",
    "      writer.add_scalar('tadvloss', tadvloss / nbatches, epoch)\n",
    "      writer.add_scalar('ttransloss', ttransloss / nbatches, epoch)\n",
    "      writer.add_scalar('realavg', realavg / nbatches, epoch)\n",
    "      writer.add_scalar('fakeavg', fakeavg / nbatches, epoch)\n",
    "\n",
    "\n",
    "      # make validation plots once per epoch\n",
    "      plotPtTheta(25, valtoys, writer, \"pt25\", epoch)\n",
    "\n",
    "      plotPtTheta(100, valtoys, writer, \"pt100\", epoch)\n",
    "\n",
    "      plotPtTheta(500, valtoys, writer, \"pt500\", epoch)\n",
    "    \n",
    "      plotPtTheta(1000, valtoys, writer, \"pt1000\", epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[nn.Sigmoid(inplace=True), nn.Tanh, nn.LeakyReLU]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO3ybE6lzKjMzApGDBeIQUE",
   "collapsed_sections": [],
   "name": "OTCalib.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
